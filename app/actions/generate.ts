'use server'

import { createClient } from '@supabase/supabase-js'
import { analyzeRefImage, type VisionAnalysis } from './vision'; 
import sharp from 'sharp'; 

const supabaseAdmin = createClient(
  process.env.NEXT_PUBLIC_SUPABASE_URL!,
  process.env.SUPABASE_SERVICE_ROLE_KEY!
)

const ARK_API_KEY = process.env.VOLC_ARK_API_KEY
const ARK_ENDPOINT_ID = process.env.VOLC_IMAGE_ENDPOINT_ID
const ARK_API_URL = "https://ark.cn-beijing.volces.com/api/v3/images/generations"

const STYLE_PRESETS: Record<string, string> = {
  "realistic": "cinematic lighting, photorealistic, 8k, masterpiece, movie still, arri alexa, high detail, real photo",
  "anime_jp": "anime style, studio ghibli, makoto shinkai, vibrant colors, clean lines",
  "anime_us": "western comic book style, marvel comics, bold lines, dynamic shading",
  "cyberpunk": "cyberpunk 2077 style, neon lights, high contrast, futuristic, tech noir",
  "noir": "film noir, black and white photography, dramatic shadows, high contrast, grainy",
  "pixar": "pixar 3d animation style, disney, unreal engine 5 render, cute, 3d character",
  "watercolor": "watercolor painting, artistic, soft edges, dreamy atmosphere",
  "ink": "traditional chinese ink painting, sumi-e, artistic, brush strokes"
};

const RATIO_MAP: Record<string, string> = {
  "16:9": "2560x1440",  
  "9:16": "1440x2560",
  "1:1": "2048x2048",   
  "4:3": "2304x1728",   
  "3:4": "1728x2304",
  "2.39:1": "3072x1280" 
};

/**
 * ğŸ’¡ è¯­ä¹‰æ£€æŸ¥ 1ï¼šéé¢éƒ¨è‚¢ä½“/ç‰©ä½“ç»†èŠ‚ (å¼€å¯ No Face æ¨¡å¼)
 * âŒ ç§»é™¤äº† 'eye', 'çœ¼', 'mouth', 'lip'
 */
function isNonFaceDetail(prompt: string): boolean {
    const keywords = [
      'hand', 'finger', 'keyboard', 'feet', 'shoe', 'typing', 'holding', 'tool', 'object', 'ground', 'sand',
      'æ‰‹', 'æŒ‡', 'é”®ç›˜', 'è„š', 'è¶³', 'é‹', 'æ²™æ»©', 'ç‰©ä½“', 'è…°', 'è…¿'
    ];
    return keywords.some(k => prompt.toLowerCase().includes(k));
}

/**
 * ğŸ’¡ è¯­ä¹‰æ£€æŸ¥ 2ï¼šé¢éƒ¨å¾®è·ç‰¹å†™ (å¼€å¯ Face æ¨¡å¼ï¼Œä½†è¿‡æ»¤è¡£æœ)
 */
function isFaceMacro(prompt: string): boolean {
    const keywords = ['eye', 'lip', 'mouth', 'nose', 'lash', 'çœ¼', 'å˜´', 'å”‡', 'é¼»', 'ç«æ¯›', 'pupil', 'iris'];
    return keywords.some(k => prompt.toLowerCase().includes(k));
}

/**
 * ğŸ§¹ ç‰¹å¾æ¸…æ´—å™¨ï¼šå¦‚æœæ˜¯ç‰¹å†™ï¼Œè¿‡æ»¤æ‰ä¸‹åŠèº«è¡£ç‰©
 */
function cleanVisualFeatures(features: string[], isCloseUp: boolean): string[] {
    if (!isCloseUp) return features;
    
    // åƒåœ¾è¯åº“ï¼šç‰¹å†™æ—¶ä¸åº”è¯¥å‡ºç°çš„è¯
    const banList = [
        'skirt', 'dress', 'pants', 'jeans', 'trousers', 'shoe', 'boot', 'sock', 'leg', 'knee', 'thigh', 'waist', 
        'standing', 'walking', 'full body', 'pleated', 'uniform', 'bag'
    ];
    
    return features.filter(f => !banList.some(ban => f.toLowerCase().includes(ban)));
}

function getStrictNegative(shotType: string, isNonFace: boolean, stylePreset: string): string {
    let base = "nsfw, low quality, bad anatomy, distortion, watermark, text, logo, extra digits, bad hands";
    
    if (stylePreset === 'realistic') {
        base += ", anime, cartoon, illustration, drawing, 2d, 3d render, sketch, painting";
    }

    if (isNonFace) {
        // è‚¢ä½“/ç‰©ä½“ç‰¹å†™ï¼šå°æ€äººè„¸
        return `${base}, face, head, eyes, portrait, person, woman, girl, man, human silhouette, look at camera`;
    } else {
        // äººåƒ/çœ¼éƒ¨ç‰¹å†™ï¼šå…è®¸è„¸ï¼Œä½†ç¦æ­¢ä¸‹åŠèº«å¹²æ‰°
        return shotType.toUpperCase().includes("CLOSE") 
            ? `${base}, legs, feet, shoes, socks, pants, skirt, lower body, full body` 
            : base;
    }
}

async function processImageRef(url: string, vision: VisionAnalysis | null, targetShot: string): Promise<string | null> {
  try {
    const res = await fetch(url);
    if (!res.ok) throw new Error(`Fetch failed`);
    const buffer = Buffer.from(await res.arrayBuffer());
    let finalBuffer: Buffer = buffer; 
    
    // åªæœ‰åœ¨å…¨æ™¯è½¬éé¢éƒ¨ç‰¹å†™æ—¶æ‰è£å‰ª
    const isTargetClose = targetShot.toUpperCase().includes("CLOSE");
    const isFaceStart = vision?.shot_type.includes("Full");

    if (isFaceStart && isTargetClose && vision?.subject_composition?.head_y_range) {
      const metadata = await sharp(buffer).metadata();
      if (metadata.width && metadata.height) {
        const [startY, endY] = vision.subject_composition.head_y_range;
        const top = Math.max(0, Math.floor(startY * metadata.height * 0.7)); 
        const cropHeight = Math.min(metadata.height - top, Math.floor((endY - startY + 0.3) * metadata.height));
        finalBuffer = await sharp(buffer)
          .extract({ left: 0, top: top, width: metadata.width, height: cropHeight })
          .resize(metadata.width, metadata.height, { fit: 'cover' })
          .toBuffer();
      }
    }
    return `data:image/jpeg;base64,${finalBuffer.toString('base64')}`;
  } catch (error) {
    console.error("[Sharp] å›¾åƒå¤„ç†å¤±è´¥:", error);
    return null;
  }
}

export async function generateShotImage(
  shotId: string | number, 
  actionPrompt: string, 
  projectId: string,
  isDraftMode: boolean, 
  stylePreset: string = 'realistic',
  aspectRatio: string = '16:9',
  shotType: string = 'MID SHOT',
  characterId?: string,
  referenceImageUrl?: string, 
  sceneImageUrl?: string      
) {
  try {
    if (!ARK_API_KEY || !ARK_ENDPOINT_ID) throw new Error("API Key Missing");

    // ğŸš¨ æ¨¡å¼åˆ¤å®š
    const isNonFace = isNonFaceDetail(actionPrompt); // æ‹æ‰‹ã€è„š -> No Face
    const isFaceMacroShot = isFaceMacro(actionPrompt); // æ‹çœ¼ã€å˜´ -> Face OK, No Body
    const isCloseUp = shotType.toUpperCase().includes("CLOSE") || isFaceMacroShot;

    console.log(`[Server] ç”Ÿæˆæ¨¡å¼: ${isNonFace ? 'è‚¢ä½“/ç‰©ä½“' : (isFaceMacroShot ? 'é¢éƒ¨å¾®è·' : 'å¸¸è§„äººåƒ')}`);

    // 1. è§†è§‰åˆ†æä¸æ¸…æ´—
    let visionAnalysis: VisionAnalysis | null = null;
    let keyFeaturesPrompt = "";
    if (referenceImageUrl) {
        try {
            visionAnalysis = await analyzeRefImage(referenceImageUrl);
            if (visionAnalysis && visionAnalysis.key_features) {
                // ğŸ”¥ æ ¸å¿ƒä¿®å¤ï¼šå¦‚æœæ˜¯ç‰¹å†™ï¼Œå¼ºåˆ¶è¿‡æ»¤æ‰ skirt, socks ç­‰å¹²æ‰°è¯
                const cleanedFeatures = cleanVisualFeatures(visionAnalysis.key_features, isCloseUp);
                
                // å¦‚æœæ˜¯ No Face æ¨¡å¼ï¼Œè¿›ä¸€æ­¥è¿‡æ»¤äº”å®˜
                const finalFeatures = cleanedFeatures.filter(f => 
                    !isNonFace || !['eye', 'lip', 'nose', 'face', 'hair'].some(k => f.includes(k.toLowerCase()))
                );

                keyFeaturesPrompt = finalFeatures.map(f => `(${f}:1.1)`).join(", ");
                console.log(`[Features] åŸå§‹: ${visionAnalysis.key_features.length} -> æ¸…æ´—å: ${finalFeatures.length} (${finalFeatures.join(',')})`);
            }
        } catch (e) { console.warn("[Vision] è·³è¿‡", e); }
    }

    // 2. Prompt ç»„è£…
    const stylePart = isDraftMode ? "sketch" : (STYLE_PRESETS[stylePreset] || STYLE_PRESETS['realistic']);
    let finalPrompt = "";
    let characterPart = "";

    // è§’è‰²æè¿°æ³¨å…¥
    if (characterId) {
      const { data: char } = await supabaseAdmin.from('characters').select('description').eq('id', characterId).single();
      if (char) {
          if (isNonFace) {
             characterPart = ""; // æ‹è„šæ—¶ä¸å¸¦äººè®¾
          } else if (isFaceMacroShot) {
             // æ‹çœ¼æ—¶ï¼Œåªä¿ç•™äººè®¾çš„å‰åŠéƒ¨åˆ†ï¼ˆé€šå¸¸æ˜¯å‘è‰²ç³è‰²ï¼‰ï¼Œæˆªæ–­è¡£æœæè¿°
             characterPart = `(Character features: ${char.description.substring(0, 50)}), `;
          } else {
             characterPart = `(Character: ${char.description}), `;
          }
      }
    }

    if (isNonFace) {
        // ğŸ¦µ è‚¢ä½“æ¨¡å¼ï¼šè„šã€æ‰‹
        finalPrompt = `((${actionPrompt}:2.8)), ${keyFeaturesPrompt}, (macro view:1.4), (strictly no people:1.8), (no face:1.8), ${stylePart}`;
    } else if (isFaceMacroShot) {
        // ğŸ‘ï¸ é¢éƒ¨å¾®è·ï¼šçœ¼ã€å˜´ (å…è®¸ Characterï¼Œä½†åœ¨ Vision é˜¶æ®µå·²è¿‡æ»¤æ‰è¡£æœ)
        finalPrompt = `((${actionPrompt}:2.5)), (macro photography:1.5), (extreme detail:1.4), (focus on face:1.2), ${characterPart} ${keyFeaturesPrompt}, ${stylePart}`;
    } else {
        // ğŸ‘¤ å¸¸è§„æ¨¡å¼
        const shotPart = isCloseUp 
            ? `(((${shotType} shot)):2.0), (head and shoulders focus:1.8), (highly detailed face:1.5)`
            : `(${shotType} shot:1.5)`;
        finalPrompt = `${shotPart}, ${actionPrompt}, ${characterPart} ${keyFeaturesPrompt}, (${stylePart}:1.4)`;
    }

    // 3. Payload
    const payload: any = {
      model: ARK_ENDPOINT_ID, 
      prompt: finalPrompt, 
      negative_prompt: getStrictNegative(shotType, isNonFace, stylePreset), 
      size: RATIO_MAP[aspectRatio] || "2560x1440", 
      n: 1,
      guidance_scale: 8.0 
    };

    // 4. Img2Img
    const targetRefImage = referenceImageUrl || sceneImageUrl;
    if (targetRefImage) {
        const base64Image = await processImageRef(targetRefImage, visionAnalysis, shotType);
        if (base64Image) {
            payload.image_url = base64Image;
            // çœ¼éƒ¨å¾®è·ä¹Ÿéœ€è¦è¾ƒé«˜å¼ºåº¦æ¥æ‘†è„±åŸå›¾æ„å›¾
            const highStrength = isNonFace || isFaceMacroShot;
            payload.strength = highStrength ? 0.92 : 0.65;
            payload.ref_strength = highStrength ? 0.92 : 0.65;
        }
    }

    // Log
    console.log("--- [DEBUG: API PAYLOAD] ---");
    console.log("PROMPT:", payload.prompt);
    console.log("NEG:", payload.negative_prompt);
    console.log("----------------------------");

    const response = await fetch(ARK_API_URL, {
      method: "POST",
      headers: { "Content-Type": "application/json", "Authorization": `Bearer ${ARK_API_KEY}` },
      body: JSON.stringify(payload)
    });
    
    const data = await response.json();
    if (!response.ok) throw new Error(data.error?.message || "Generation Failed");

    return processResponse(data, shotId, projectId);

  } catch (error: any) {
    console.error(error);
    return { success: false, message: error.message };
  }
}

async function processResponse(data: any, shotId: string | number, projectId: string) {
    const imageUrl = data.data?.[0]?.url;
    if (!imageUrl) throw new Error("No image url returned");
    const imageRes = await fetch(imageUrl);
    const buffer = Buffer.from(await imageRes.arrayBuffer());
    const fileName = `cineflow/${projectId}/${Date.now()}_${shotId}.png`;
    await supabaseAdmin.storage.from('images').upload(fileName, buffer, { contentType: 'image/png', upsert: true });
    const { data: { publicUrl } } = supabaseAdmin.storage.from('images').getPublicUrl(fileName);
    return { success: true, url: publicUrl };
}